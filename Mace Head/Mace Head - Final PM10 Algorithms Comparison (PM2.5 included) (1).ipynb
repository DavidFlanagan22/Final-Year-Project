{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mace Head - Final PM10 Algorithms Comparison (PM2.5 included)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the various packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# imports necessary for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "# regression algorithms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# metrics for evaluating regression models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error, explained_variance_score, max_error\n",
    "\n",
    "from time import process_time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\User\\\\Final Year Project/MaceHead_FileforML.csv', thousands=',', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Date data type for later date selection\n",
    "df['Date'] = df['Date'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('indrain', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('indtemp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('indwetb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('indwdsp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('indwddir', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('wetb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('dewpt', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('vappr', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('rhum', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 46948\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows of data: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all Rows with PM10 > 70 $\\mu g / m^{3}$\n",
    "\n",
    "In my data analysis work in previous notebooks, these values are suspiciously high and hence they are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of rows deleted is: 93 out of 46948 original rows\n"
     ]
    }
   ],
   "source": [
    "PMdf = df[(df['PM10'] < 70)]\n",
    "\n",
    "print('The Number of rows deleted is: {} out of {} original rows'.format((len(df) - len(PMdf)), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alter data to remove zero values for later input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "PMdf['Ozone'] = PMdf['Ozone']+1.00\n",
    "PMdf['rain'] = PMdf['rain']+1.00\n",
    "PMdf['PM10'] = PMdf['PM10']+1.00\n",
    "PMdf['wdsp'] = PMdf['wdsp']+1.00\n",
    "PMdf['temp'] = PMdf['temp']+7.50\n",
    "PMdf['Hour'] = PMdf['Hour']+1.00\n",
    "PMdf['wddir'] = PMdf['wddir']/360 + 1.00\n",
    "PMdf['msl'] = PMdf['msl']/1000\n",
    "\n",
    "df['Ozone'] = df['Ozone']+1.00\n",
    "df['rain'] = df['rain']+1.00\n",
    "df['PM10'] = df['PM10']+1.00\n",
    "df['wdsp'] = df['wdsp']+1.00\n",
    "df['temp'] = df['temp']+7.50\n",
    "df['Hour'] = df['Hour']+1.00\n",
    "df['wddir'] = df['wddir']/360 + 1.00\n",
    "df['msl'] = df['msl']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select specific time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Yeardf(Frame, Date1, Date2):\n",
    "    import datetime\n",
    "    Sorteddf = Frame[(Frame['Date'] > Date1) & (Frame['Date']< Date2)]\n",
    "    return Sorteddf\n",
    "Year2014PM = Yeardf(PMdf, \"2014-03-01\", \"2015-01-01\")\n",
    "Year2015PM = Yeardf(PMdf, \"2015-01-01\", \"2016-01-01\")\n",
    "Year2016PM = Yeardf(PMdf, \"2016-01-01\", \"2017-01-01\")\n",
    "Year2017PM = Yeardf(PMdf, \"2017-01-01\", \"2018-01-01\")\n",
    "Year2018PM = Yeardf(PMdf, \"2018-01-01\", \"2019-01-01\")\n",
    "Year2019PM = Yeardf(PMdf, \"2019-01-01\", \"2020-01-01\")\n",
    "Year2020PM = Yeardf(PMdf, \"2020-01-01\", \"2021-01-01\")\n",
    "TotalYearsPM = Yeardf(PMdf, \"2015-01-01\", \"2020-01-01\")\n",
    "\n",
    "Year2014 = Yeardf(df, \"2014-03-01\", \"2015-01-01\")\n",
    "Year2015 = Yeardf(df, \"2015-01-01\", \"2016-01-01\")\n",
    "Year2016 = Yeardf(df, \"2016-01-01\", \"2017-01-01\")\n",
    "Year2017 = Yeardf(df, \"2017-01-01\", \"2018-01-01\")\n",
    "Year2018 = Yeardf(df, \"2018-01-01\", \"2019-01-01\")\n",
    "Year2019 = Yeardf(df, \"2019-01-01\", \"2020-01-01\")\n",
    "Year2020 = Yeardf(df, \"2020-01-01\", \"2021-01-01\")\n",
    "TotalYears = Yeardf(df, \"2015-01-01\", \"2020-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33914\n",
      "33840\n"
     ]
    }
   ],
   "source": [
    "print(len(TotalYears))\n",
    "print(len(TotalYearsPM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year2014.drop('Date', axis=1, inplace=True)\n",
    "Year2015.drop('Date', axis=1, inplace=True)\n",
    "Year2016.drop('Date', axis=1, inplace=True)\n",
    "Year2017.drop('Date', axis=1, inplace=True)\n",
    "Year2018.drop('Date', axis=1, inplace=True)\n",
    "Year2019.drop('Date', axis=1, inplace=True)\n",
    "TotalYears.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year2014PM.drop('Date', axis=1, inplace=True)\n",
    "Year2015PM.drop('Date', axis=1, inplace=True)\n",
    "Year2016PM.drop('Date', axis=1, inplace=True)\n",
    "Year2017PM.drop('Date', axis=1, inplace=True)\n",
    "Year2018PM.drop('Date', axis=1, inplace=True)\n",
    "Year2019PM.drop('Date', axis=1, inplace=True)\n",
    "TotalYearsPM.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>PM25</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>89.80865</td>\n",
       "      <td>7.17</td>\n",
       "      <td>21.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0169</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>89.74878</td>\n",
       "      <td>8.23</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.527778</td>\n",
       "      <td>89.46938</td>\n",
       "      <td>4.91</td>\n",
       "      <td>19.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1.0145</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.527778</td>\n",
       "      <td>89.38955</td>\n",
       "      <td>5.44</td>\n",
       "      <td>17.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0136</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.527778</td>\n",
       "      <td>88.77089</td>\n",
       "      <td>4.65</td>\n",
       "      <td>17.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.0110</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.472222</td>\n",
       "      <td>88.49149</td>\n",
       "      <td>4.60</td>\n",
       "      <td>19.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>87.35394</td>\n",
       "      <td>4.43</td>\n",
       "      <td>14.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0087</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.527778</td>\n",
       "      <td>86.21639</td>\n",
       "      <td>5.05</td>\n",
       "      <td>11.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0090</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>84.69966</td>\n",
       "      <td>6.05</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.0087</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>83.58207</td>\n",
       "      <td>5.59</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.0082</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>82.96340</td>\n",
       "      <td>4.99</td>\n",
       "      <td>12.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.0069</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>83.08314</td>\n",
       "      <td>2.79</td>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>81.38680</td>\n",
       "      <td>4.99</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>19.3</td>\n",
       "      <td>1.0048</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>80.06963</td>\n",
       "      <td>8.12</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>79.59067</td>\n",
       "      <td>9.41</td>\n",
       "      <td>16.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.0053</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.611111</td>\n",
       "      <td>79.15161</td>\n",
       "      <td>10.62</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.638889</td>\n",
       "      <td>82.58422</td>\n",
       "      <td>10.60</td>\n",
       "      <td>17.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>1.0089</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.694444</td>\n",
       "      <td>86.67540</td>\n",
       "      <td>10.39</td>\n",
       "      <td>17.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.0112</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>87.69321</td>\n",
       "      <td>10.03</td>\n",
       "      <td>17.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>88.43162</td>\n",
       "      <td>10.05</td>\n",
       "      <td>17.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1.0150</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>88.37175</td>\n",
       "      <td>8.64</td>\n",
       "      <td>16.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6091</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>89.66895</td>\n",
       "      <td>10.17</td>\n",
       "      <td>19.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1.0182</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>88.07239</td>\n",
       "      <td>12.72</td>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.0195</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>85.07884</td>\n",
       "      <td>10.25</td>\n",
       "      <td>17.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>84.10095</td>\n",
       "      <td>10.10</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.0214</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>83.88142</td>\n",
       "      <td>12.76</td>\n",
       "      <td>22.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.0225</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>84.91919</td>\n",
       "      <td>13.50</td>\n",
       "      <td>24.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.0238</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>85.95695</td>\n",
       "      <td>9.42</td>\n",
       "      <td>18.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.0245</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>87.11446</td>\n",
       "      <td>11.20</td>\n",
       "      <td>20.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.0266</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>88.85071</td>\n",
       "      <td>10.57</td>\n",
       "      <td>26.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39954</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>79.81019</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39955</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>80.98766</td>\n",
       "      <td>3.11</td>\n",
       "      <td>10.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39956</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0286</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>78.71256</td>\n",
       "      <td>4.29</td>\n",
       "      <td>11.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39957</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.194444</td>\n",
       "      <td>76.07823</td>\n",
       "      <td>5.49</td>\n",
       "      <td>13.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39958</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0293</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.194444</td>\n",
       "      <td>75.65914</td>\n",
       "      <td>4.03</td>\n",
       "      <td>11.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39959</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1.0295</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.194444</td>\n",
       "      <td>77.85441</td>\n",
       "      <td>1.18</td>\n",
       "      <td>7.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39960</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0287</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>77.67479</td>\n",
       "      <td>2.89</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39961</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>73.40400</td>\n",
       "      <td>3.35</td>\n",
       "      <td>9.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39962</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.0293</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>71.74756</td>\n",
       "      <td>4.05</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39963</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.0289</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.194444</td>\n",
       "      <td>71.28855</td>\n",
       "      <td>2.30</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39964</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.0296</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>68.13535</td>\n",
       "      <td>2.77</td>\n",
       "      <td>8.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39965</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.0293</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>67.89586</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39966</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.0288</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>66.57870</td>\n",
       "      <td>3.30</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39967</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.0291</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>63.84459</td>\n",
       "      <td>4.07</td>\n",
       "      <td>10.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39968</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.0294</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>64.10403</td>\n",
       "      <td>4.99</td>\n",
       "      <td>11.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39969</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0302</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>63.30575</td>\n",
       "      <td>5.28</td>\n",
       "      <td>10.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39970</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0306</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>60.77122</td>\n",
       "      <td>3.17</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39971</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.0312</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>58.97509</td>\n",
       "      <td>3.52</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39972</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.0311</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>59.31435</td>\n",
       "      <td>2.47</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39973</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1.0303</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>58.59590</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39974</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.0295</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>60.13259</td>\n",
       "      <td>2.59</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39975</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1.0291</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>57.09913</td>\n",
       "      <td>4.01</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39976</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.0291</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>51.95022</td>\n",
       "      <td>5.03</td>\n",
       "      <td>10.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39977</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1.0288</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.305556</td>\n",
       "      <td>47.02084</td>\n",
       "      <td>6.23</td>\n",
       "      <td>11.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39978</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1.0291</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.305556</td>\n",
       "      <td>47.99874</td>\n",
       "      <td>6.63</td>\n",
       "      <td>12.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39979</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1.0294</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>56.32080</td>\n",
       "      <td>4.99</td>\n",
       "      <td>13.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39980</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.0292</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>60.61156</td>\n",
       "      <td>3.18</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1.0291</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>57.07917</td>\n",
       "      <td>3.79</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39982</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.0288</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>45.78351</td>\n",
       "      <td>6.90</td>\n",
       "      <td>19.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39983</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.0286</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>51.31160</td>\n",
       "      <td>4.56</td>\n",
       "      <td>18.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33840 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hour  rain  temp     msl  wdsp     wddir     Ozone   PM25   PM10\n",
       "6070    2.0   1.0  18.1  1.0177  23.0  1.555556  89.80865   7.17  21.43\n",
       "6071    3.0   1.0  18.1  1.0169  22.0  1.555556  89.74878   8.23  23.00\n",
       "6072    4.0   1.1  18.0  1.0161  20.0  1.527778  89.46938   4.91  19.55\n",
       "6073    5.0   1.8  17.9  1.0145  21.0  1.527778  89.38955   5.44  17.54\n",
       "6074    6.0   2.9  17.7  1.0136  24.0  1.527778  88.77089   4.65  17.64\n",
       "6075    7.0   3.6  17.8  1.0110  24.0  1.472222  88.49149   4.60  19.89\n",
       "6076    8.0   3.4  18.4  1.0096  29.0  1.500000  87.35394   4.43  14.82\n",
       "6077    9.0   1.5  18.8  1.0087  30.0  1.527778  86.21639   5.05  11.81\n",
       "6078   10.0   1.1  18.8  1.0090  31.0  1.555556  84.69966   6.05  11.83\n",
       "6079   11.0   1.0  18.9  1.0087  29.0  1.555556  83.58207   5.59  11.83\n",
       "6080   12.0   1.7  18.9  1.0082  28.0  1.583333  82.96340   4.99  12.17\n",
       "6081   13.0   1.1  18.7  1.0069  26.0  1.555556  83.08314   2.79   8.60\n",
       "6082   14.0   1.8  19.0  1.0054  28.0  1.555556  81.38680   4.99  10.40\n",
       "6083   15.0   1.1  19.3  1.0048  32.0  1.583333  80.06963   8.12  14.99\n",
       "6084   16.0   2.1  19.2  1.0049  32.0  1.583333  79.59067   9.41  16.39\n",
       "6085   17.0   1.1  19.4  1.0053  33.0  1.611111  79.15161  10.62  18.07\n",
       "6086   18.0   1.0  18.6  1.0070  29.0  1.638889  82.58422  10.60  17.78\n",
       "6087   19.0   1.0  18.2  1.0089  25.0  1.694444  86.67540  10.39  17.32\n",
       "6088   20.0   1.0  17.4  1.0112  30.0  1.722222  87.69321  10.03  17.14\n",
       "6089   21.0   1.0  17.2  1.0128  31.0  1.750000  88.43162  10.05  17.79\n",
       "6090   22.0   1.0  16.4  1.0150  32.0  1.777778  88.37175   8.64  16.59\n",
       "6091   23.0   1.0  16.4  1.0161  33.0  1.777778  89.66895  10.17  19.09\n",
       "6092   24.0   1.0  15.1  1.0182  33.0  1.750000  88.07239  12.72  23.36\n",
       "6093    1.0   1.0  15.5  1.0195  33.0  1.777778  85.07884  10.25  17.52\n",
       "6094    2.0   1.2  14.8  1.0203  33.0  1.750000  84.10095  10.10  18.09\n",
       "6095    3.0   1.0  15.3  1.0214  33.0  1.750000  83.88142  12.76  22.74\n",
       "6096    4.0   1.0  15.6  1.0225  34.0  1.750000  84.91919  13.50  24.18\n",
       "6097    5.0   1.0  15.3  1.0238  32.0  1.777778  85.95695   9.42  18.69\n",
       "6098    6.0   1.0  14.9  1.0245  36.0  1.777778  87.11446  11.20  20.18\n",
       "6099    8.0   1.1  14.7  1.0266  31.0  1.777778  88.85071  10.57  26.37\n",
       "...     ...   ...   ...     ...   ...       ...       ...    ...    ...\n",
       "39954  19.0   1.0  15.2  1.0272  15.0  1.166667  79.81019   0.80   6.71\n",
       "39955  20.0   1.0  15.0  1.0272  18.0  1.166667  80.98766   3.11  10.29\n",
       "39956  21.0   1.0  15.0  1.0286  17.0  1.166667  78.71256   4.29  11.84\n",
       "39957  22.0   1.0  14.5  1.0290  16.0  1.194444  76.07823   5.49  13.22\n",
       "39958  23.0   1.0  14.5  1.0293  16.0  1.194444  75.65914   4.03  11.43\n",
       "39959  24.0   1.0  14.6  1.0295  16.0  1.194444  77.85441   1.18   7.16\n",
       "39960   1.0   1.0  14.5  1.0287  18.0  1.166667  77.67479   2.89   8.50\n",
       "39961   2.0   1.0  14.3  1.0290  19.0  1.222222  73.40400   3.35   9.62\n",
       "39962   3.0   1.0  14.1  1.0293  18.0  1.222222  71.74756   4.05   9.94\n",
       "39963   4.0   1.0  14.2  1.0289  16.0  1.194444  71.28855   2.30   8.08\n",
       "39964   5.0   1.0  13.9  1.0296  18.0  1.222222  68.13535   2.77   8.30\n",
       "39965   6.0   1.0  13.8  1.0293  18.0  1.222222  67.89586   2.87   8.80\n",
       "39966   7.0   1.0  14.1  1.0288  17.0  1.222222  66.57870   3.30   9.35\n",
       "39967   8.0   1.0  13.9  1.0291  17.0  1.250000  63.84459   4.07  10.33\n",
       "39968   9.0   1.0  13.9  1.0294  12.0  1.250000  64.10403   4.99  11.26\n",
       "39969  10.0   1.0  14.5  1.0302  14.0  1.250000  63.30575   5.28  10.83\n",
       "39970  11.0   1.0  14.5  1.0306  14.0  1.250000  60.77122   3.17   7.36\n",
       "39971  12.0   1.0  13.9  1.0312  16.0  1.250000  58.97509   3.52   8.41\n",
       "39972  13.0   1.0  14.2  1.0311  14.0  1.250000  59.31435   2.47   7.47\n",
       "39973  14.0   1.0  14.6  1.0303  11.0  1.250000  58.59590   1.97   6.26\n",
       "39974  15.0   1.0  14.8  1.0295  11.0  1.250000  60.13259   2.59   7.31\n",
       "39975  16.0   1.0  15.1  1.0291  11.0  1.250000  57.09913   4.01   8.75\n",
       "39976  17.0   1.0  14.8  1.0291  11.0  1.277778  51.95022   5.03  10.21\n",
       "39977  18.0   1.0  14.6  1.0288  11.0  1.305556  47.02084   6.23  11.93\n",
       "39978  19.0   1.0  14.8  1.0291  10.0  1.305556  47.99874   6.63  12.36\n",
       "39979  20.0   1.0  15.1  1.0294   7.0  1.333333  56.32080   4.99  13.77\n",
       "39980  21.0   1.0  15.7  1.0292   8.0  1.388889  60.61156   3.18  14.83\n",
       "39981  22.0   1.0  16.1  1.0291  10.0  1.416667  57.07917   3.79  14.10\n",
       "39982  23.0   1.0  15.7  1.0288  10.0  1.416667  45.78351   6.90  19.16\n",
       "39983  24.0   1.0  15.7  1.0286  10.0  1.416667  51.31160   4.56  18.12\n",
       "\n",
       "[33840 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check that it looks good\n",
    "display(TotalYearsPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to be called during Machine Learning Algorithm operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_test, y_test, model):\n",
    "    \n",
    "    # compute predictiond for the test set\n",
    "    _predicted_values = model.predict(X_test)\n",
    "    # compute metrics\n",
    "    _mse = mean_squared_error(y_test, _predicted_values)\n",
    "    _mae = mean_absolute_error(y_test, _predicted_values)\n",
    "    _r2 = r2_score(y_test, _predicted_values)\n",
    "    _meae = median_absolute_error(y_test, _predicted_values)\n",
    "    _evs = explained_variance_score(y_test, _predicted_values)\n",
    "    _me = max_error(y_test, _predicted_values)      \n",
    "    return _mse, _mae, _r2, _meae, _evs, _me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddColumnNames(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(data=X, columns=self.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Function with preprocess built into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RandomForest(Name, N_Year, N, printCV, printgraph, N_Features, Max_Depth, ratio, PM):\n",
    "    \n",
    "    Data = N_Year\n",
    "    \n",
    "    names_all = [c for c in Data if c not in ['PM10']]\n",
    "\n",
    "    # define column groups with the same data preparation\n",
    "    names_outliers = ['wdsp','temp','rain','Ozone','Hour','wddir','msl', 'PM25']\n",
    "    names_no_outliers = list(set(names_all) - set(names_outliers))\n",
    "    \n",
    "    y = Data['PM10']\n",
    "    X = Data.drop('PM10', axis=1).values\n",
    "    \n",
    "    preprocess_pipeline = make_pipeline(\n",
    "    AddColumnNames(columns=names_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()\n",
    "        )),\n",
    "        (\"no_outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()  \n",
    "        ))\n",
    "    ])\n",
    ")\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, shuffle=True)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                        ('regresson', RandomForestRegressor(n_estimators=100))])\n",
    "\n",
    "    \n",
    "    #print(len(Data))\n",
    "    \n",
    "    \n",
    "    N_FEATURES_OPTIONS = [N_Features]\n",
    "    MAX_DEPTH_OPTIONS = [Max_Depth]\n",
    "\n",
    "    param_grid = [\n",
    "        {\n",
    "            'reduce_dim': [PCA(iterated_power=7)],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "            'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')),RFE(LinearRegression())],\n",
    "            'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "            'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [FastICA( algorithm='deflation')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "            'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "        },\n",
    "    ]    \n",
    "\n",
    "    search = GridSearchCV(pipe, param_grid, cv=10, iid = False, refit=True)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    if printCV == 0:\n",
    "        print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "        print(\"Best parameters: \", search.best_params_)\n",
    "    \n",
    "        \n",
    " \n",
    "    # store the best params and best model for later use\n",
    "    RF_best_params = search.best_params_\n",
    "    RF_best_model = search.best_estimator_\n",
    "    \n",
    "    if printgraph == 0:\n",
    "        model = RandomForestRegressor()\n",
    "        visualizer = PredictionError(model)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        visualizer.show()                 # Finalize and render the figure\n",
    "    \n",
    "    \n",
    "    RF_mse, RF_mae, RF_r2, RF_meae, RF_evs, RF_me = evaluate_model(X_test, y_test, RF_best_model)\n",
    "    \n",
    "    Title = np.array([Name])\n",
    "    Range = np.array([N])\n",
    "    Features = np.array([N_Features])\n",
    "    Depth = np.array([Max_Depth])\n",
    "    Split = np.array([ratio])\n",
    "    PM_70 = np.array([PM])\n",
    "    MSE  = np.array([RF_mse])\n",
    "    MAE  = np.array([RF_mae])\n",
    "    R2   = np.array([RF_r2])\n",
    "    MEAE = np.array([RF_meae])\n",
    "    ME   = np.array([RF_me])\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(list(zip(Title, Range, Features, Depth, Split, PM_70, MSE, MAE, R2, MEAE, ME)), columns =['Algorithm', 'Year', 'N Features', 'Max Depth', 'Test-Train Split', 'PM10 > 70 Removed', 'MSE', 'MAE', 'R2', 'MEAE', 'ME'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomForest() missing 1 required positional argument: 'PM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForest() missing 1 required positional argument: 'PM'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RandomForest('Random Forest', TotalYears, '2015-2019', 0, 0, 8, 0.3, 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "Function with preprocess built into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def GradientBoosting(Name, N_Year, N, printCV, printgraph, N_Features, Max_Depth, ratio, PM):\n",
    "    Data = N_Year\n",
    "    \n",
    "    names_all = [c for c in Data if c not in ['PM10']]\n",
    "\n",
    "    # define column groups with the same data preparation\n",
    "    names_outliers = ['wdsp','temp','rain','Ozone','Hour','wddir','msl', 'PM25']\n",
    "    names_no_outliers = list(set(names_all) - set(names_outliers))\n",
    "    \n",
    "    y = Data['PM10']\n",
    "    X = Data.drop('PM10', axis=1).values\n",
    "    \n",
    "    preprocess_pipeline = make_pipeline(\n",
    "    AddColumnNames(columns=names_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()\n",
    "        )),\n",
    "        (\"no_outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()  \n",
    "        ))\n",
    "    ])\n",
    ")\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, shuffle=True)\n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                           ('reduce_dim', 'passthrough'),\n",
    "                           ('regresson', GradientBoostingRegressor())])\n",
    "\n",
    "\n",
    "\n",
    "    N_FEATURES_OPTIONS = [N_Features]\n",
    "    MAX_DEPTH_OPTIONS = [Max_Depth]\n",
    "\n",
    "\n",
    "    param_grid = [\n",
    "         {\n",
    "            'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [FactorAnalysis(svd_method='randomized'), FactorAnalysis(svd_method='lapack')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [PCA(iterated_power=7)],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "            'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')),RFE(LinearRegression())],\n",
    "            'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "            'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "        }\n",
    "\n",
    "\n",
    "    ]\n",
    "    search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=10, iid=False, refit=True)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    if printCV == 0:\n",
    "        print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "        print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "    # store the best params and best model for later use\n",
    "    GB_best_params = search.best_params_\n",
    "    GB_best_model = search.best_estimator_\n",
    "    \n",
    "    if printgraph == 0:\n",
    "        model = GradientBoostingRegressor()\n",
    "        visualizer = PredictionError(model)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        visualizer.show()                 # Finalize and render the figure\n",
    "\n",
    "    GB_mse, GB_mae, GB_r2, GB_meae, GB_evs, GB_me = evaluate_model(X_test, y_test, GB_best_model)\n",
    "    \n",
    "    Title = np.array([Name])\n",
    "    Range = np.array([N])\n",
    "    Features = np.array([N_Features])\n",
    "    Depth = np.array([Max_Depth])\n",
    "    Split = np.array([ratio])\n",
    "    PM_70 = np.array([PM])\n",
    "    MSE  = np.array([GB_mse])\n",
    "    MAE  = np.array([GB_mae])\n",
    "    R2   = np.array([GB_r2])\n",
    "    MEAE = np.array([GB_meae])\n",
    "    ME   = np.array([GB_me])\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(list(zip(Title, Range, Features, Depth, Split, PM_70, MSE, MAE, R2, MEAE, ME)), columns =['Algorithm', 'Year', 'N Features', 'Max Depth', 'Test-Train Split', 'PM10 > 70 Removed', 'MSE', 'MAE', 'R2', 'MEAE', 'ME'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GradientBoosting() missing 2 required positional arguments: 'ratio' and 'PM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: GradientBoosting() missing 2 required positional arguments: 'ratio' and 'PM'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GradientBoosting('Gradient Boosting', TotalYears, '2015-2019', 0, 0, 8, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN\n",
    "Function with preprocess built into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def ANN(Name, N_Year, N, printCV, printgraph, N_Features, ratio, PM):\n",
    "    Data = N_Year\n",
    "    \n",
    "    names_all = [c for c in Data if c not in ['PM10']]\n",
    "\n",
    "    # define column groups with the same data preparation\n",
    "    names_outliers = ['wdsp','temp','rain','Ozone','Hour','wddir','msl', 'PM25']\n",
    "    names_no_outliers = list(set(names_all) - set(names_outliers))\n",
    "    \n",
    "    y = Data['PM10']\n",
    "    X = Data.drop('PM10', axis=1).values\n",
    "    \n",
    "    preprocess_pipeline = make_pipeline(\n",
    "    AddColumnNames(columns=names_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()\n",
    "        )),\n",
    "        (\"no_outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()  \n",
    "        ))\n",
    "    ])\n",
    ")\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, shuffle=True)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', MLPRegressor ())])\n",
    "\n",
    "\n",
    "\n",
    "    ALPHA = [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "    HIDDEN_LAYER_SIZES = [(6),(11,11),(7,7,7)] \n",
    "    SOLVER = ['adam'] \n",
    "    ACTIVATION = ['relu','tanh','identity','logistic'] \n",
    "    LEARNING_RATE = ['constant','invscaling','adaptive']\n",
    "    N_FEATURES_OPTIONS = [N_Features]\n",
    "    MAX_ITER = [500]\n",
    "\n",
    "    param_grid = [\n",
    "         {\n",
    "            'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [FactorAnalysis(svd_method='randomized'), FactorAnalysis(svd_method='lapack')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "        },\n",
    "\n",
    "    ]\n",
    "    search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=10, iid=False, refit=True)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    if printCV == 0:\n",
    "        print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "        print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "     # store the best params and best model for later use\n",
    "    MLP_best_params = search.best_params_\n",
    "    MLP_best_model = search.best_estimator_\n",
    "    \n",
    "    if printgraph == 0:\n",
    "        model = MLPRegressor()\n",
    "        visualizer = PredictionError(model)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        visualizer.show()                 # Finalize and render the figure\n",
    "\n",
    "    MLP_mse, MLP_mae, MLP_r2, MLP_meae, MLP_evs, MLP_me = evaluate_model(X_test, y_test, MLP_best_model)\n",
    "    \n",
    "    Title = np.array([Name])\n",
    "    Range = np.array([N])\n",
    "    Features = np.array([N_Features])\n",
    "    #Depth = np.array([Max_Depth])\n",
    "    Split = np.array([ratio])\n",
    "    PM_70 = np.array([PM])\n",
    "    MSE  = np.array([MLP_mse])\n",
    "    MAE  = np.array([MLP_mae])\n",
    "    R2   = np.array([MLP_r2])\n",
    "    MEAE = np.array([MLP_meae])\n",
    "    ME   = np.array([MLP_me])\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(list(zip(Title, Range, Features, Split, PM_70, MSE, MAE, R2, MEAE, ME)), columns =['Algorithm', 'Year', 'N Features', 'Test-Train Split', 'PM10 > 70 Removed', 'MSE', 'MAE', 'R2', 'MEAE', 'ME'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.328:\n",
      "Best parameters:  {'reduce_dim': FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=8,\n",
      "               noise_variance_init=None, random_state=0, svd_method='lapack',\n",
      "               tol=0.01), 'reduce_dim__n_components': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>82.93169</td>\n",
       "      <td>6.433297</td>\n",
       "      <td>0.320393</td>\n",
       "      <td>4.952278</td>\n",
       "      <td>132.405164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm       Year  N Features  Test-Train Split PM10 > 70 Removed  \\\n",
       "0       ANN  2015-2019           8               0.3               Yes   \n",
       "\n",
       "        MSE       MAE        R2      MEAE          ME  \n",
       "0  82.93169  6.433297  0.320393  4.952278  132.405164  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ANN('ANN', TotalYears, '2015-2019', 0, 0, 8, 0.3, 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Function with preprocess built into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def LRegress(Name, N_Year, N, printCV, printgraph, N_Features, ratio, PM):\n",
    "    Data = N_Year\n",
    "    \n",
    "    names_all = [c for c in Data if c not in ['PM10']]\n",
    "\n",
    "    # define column groups with the same data preparation\n",
    "    names_outliers = ['wdsp','temp','rain','Ozone','Hour','wddir','msl', 'PM25']\n",
    "    names_no_outliers = list(set(names_all) - set(names_outliers))\n",
    "    \n",
    "    y = Data['PM10']\n",
    "    X = Data.drop('PM10', axis=1).values\n",
    "    \n",
    "    preprocess_pipeline = make_pipeline(\n",
    "    AddColumnNames(columns=names_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()\n",
    "        )),\n",
    "        (\"no_outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()  \n",
    "        ))\n",
    "    ])\n",
    "    )\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, shuffle=True)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', LinearRegression())])\n",
    "\n",
    "\n",
    "\n",
    "    N_FEATURES_OPTIONS = [N_Features]\n",
    "    NORMALIZE_OPTIONS = [False, True]\n",
    "\n",
    "    param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')),RFE(LinearRegression())],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [FastICA( algorithm='deflation')],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "    search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=10, iid=False, refit=True)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    if printCV == 0:\n",
    "        print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "        print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "     # store the best params and best model for later use\n",
    "    LR_best_params = search.best_params_\n",
    "    LR_best_model = search.best_estimator_\n",
    "    \n",
    "    if printgraph == 0:\n",
    "        model = LinearRegression()\n",
    "        visualizer = PredictionError(model)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        visualizer.show()                 # Finalize and render the figure\n",
    "\n",
    "    LR_mse, LR_mae, LR_r2, LR_meae, LR_evs, LR_me = evaluate_model(X_test, y_test, LR_best_model)\n",
    "    \n",
    "    Title = np.array([Name])\n",
    "    Range = np.array([N])\n",
    "    Features = np.array([N_Features])\n",
    "    #Depth = np.array([Max_Depth])\n",
    "    Split = np.array([ratio])\n",
    "    PM_70 = np.array([PM])\n",
    "    MSE  = np.array([LR_mse])\n",
    "    MAE  = np.array([LR_mae])\n",
    "    R2   = np.array([LR_r2])\n",
    "    MEAE = np.array([LR_meae])\n",
    "    ME   = np.array([LR_me])\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(list(zip(Title, Range, Features, Split, PM_70, MSE, MAE, R2, MEAE, ME)), columns =['Algorithm', 'Year', 'N Features', 'Test-Train Split', 'PM10 > 70 Removed', 'MSE', 'MAE', 'R2', 'MEAE', 'ME'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LRegress() missing 1 required positional argument: 'PM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: LRegress() missing 1 required positional argument: 'PM'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LRegress('Linear Regression', TotalYears, '2015-2019', 0, 0, 8, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "Function with preprocess built into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def SVM(Name, N_Year, N, printCV, printgraph, N_Features, ratio, PM):\n",
    "    Data = N_Year\n",
    "    \n",
    "    names_all = [c for c in Data if c not in ['PM10']]\n",
    "\n",
    "    # define column groups with the same data preparation\n",
    "    names_outliers = ['wdsp','temp','rain','Ozone','Hour','wddir','msl', 'PM25']\n",
    "    names_no_outliers = list(set(names_all) - set(names_outliers))\n",
    "    \n",
    "    y = Data['PM10']\n",
    "    X = Data.drop('PM10', axis=1).values\n",
    "    \n",
    "    preprocess_pipeline = make_pipeline(\n",
    "    AddColumnNames(columns=names_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()\n",
    "        )),\n",
    "        (\"no_outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()  \n",
    "        ))\n",
    "    ])\n",
    ")\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, shuffle=True)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', SVR())])\n",
    "\n",
    "\n",
    "\n",
    "    KERNEL = ['linear']\n",
    "    C = [300]\n",
    "    GAMMA = ['auto']\n",
    "    N_FEATURES_OPTIONS = [N_Features]\n",
    "\n",
    "\n",
    "    param_grid = [\n",
    "         {\n",
    "            'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "        },\n",
    "        {\n",
    "            'reduce_dim': [FactorAnalysis(svd_method='randomized'), FactorAnalysis(svd_method='lapack')],\n",
    "            'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=10, iid=False, refit=True)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    if printCV == 0:\n",
    "        print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "        print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "     # store the best params and best model for later use\n",
    "    SVR_best_params = search.best_params_\n",
    "    SVR_best_model = search.best_estimator_\n",
    "    \n",
    "    if printgraph == 0:\n",
    "        model = SVR()\n",
    "        visualizer = PredictionError(model)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        visualizer.show()                 # Finalize and render the figure\n",
    "\n",
    "    SVR_mse, SVR_mae, SVR_r2, SVR_meae, SVR_evs, SVR_me = evaluate_model(X_test, y_test, SVR_best_model)\n",
    "    \n",
    "    Title = np.array([Name])\n",
    "    Range = np.array([N])\n",
    "    Features = np.array([N_Features])\n",
    "    #Depth = np.array([Max_Depth])\n",
    "    Split = np.array([ratio])\n",
    "    PM_70 = np.array([PM])\n",
    "    MSE  = np.array([SVR_mse])\n",
    "    MAE  = np.array([SVR_mae])\n",
    "    R2   = np.array([SVR_r2])\n",
    "    MEAE = np.array([SVR_meae])\n",
    "    ME   = np.array([SVR_me])\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(list(zip(Title, Range, Features, Split, PM_70, MSE, MAE, R2, MEAE, ME)), columns =['Algorithm', 'Year', 'N Features', 'Test-Train Split', 'PM10 > 70 Removed', 'MSE', 'MAE', 'R2', 'MEAE', 'ME'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Permutations of each Algorithm to Identify most optimised Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_6_12_NO = RandomForest('Random Forest', TotalYears, '2015-2019', 1, 1, 6, 12, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_7_12_NO = RandomForest('Random Forest', TotalYears, '2015-2019', 1, 1, 7, 12, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_12_NO = RandomForest('Random Forest', TotalYears, '2015-2019', 1, 1, 8, 12, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_12_NO_5 = RandomForest('Random Forest', TotalYears, '2015-2019', 1, 1, 8, 12, 0.5, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_12_NO_3 = RandomForest('Random Forest', TotalYears, '2015-2019', 1, 1, 8, 12, 0.3, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_12_YES_3 = RandomForest('Random Forest', TotalYearsPM, '2015-2019', 1, 1, 8, 12, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_14_YES_3 = RandomForest('Random Forest', TotalYearsPM, '2015-2019', 1, 1, 8, 14, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_16_YES_3 = RandomForest('Random Forest', TotalYearsPM, '2015-2019', 1, 1, 8, 16, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 38min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_18_YES_3 = RandomForest('Random Forest', TotalYearsPM, '2015-2019', 1, 1, 8, 18, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 38min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_8_20_YES_3 = RandomForest('Random Forest', TotalYearsPM, '2015-2019', 1, 1, 8, 20, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>32.944</td>\n",
       "      <td>4.015</td>\n",
       "      <td>0.722</td>\n",
       "      <td>2.881</td>\n",
       "      <td>69.833</td>\n",
       "      <td>11m 58s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>33.314</td>\n",
       "      <td>4.042</td>\n",
       "      <td>0.722</td>\n",
       "      <td>3.047</td>\n",
       "      <td>102.497</td>\n",
       "      <td>11m 38s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>32.862</td>\n",
       "      <td>3.992</td>\n",
       "      <td>0.728</td>\n",
       "      <td>2.985</td>\n",
       "      <td>117.944</td>\n",
       "      <td>12m 27s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>30.801</td>\n",
       "      <td>3.854</td>\n",
       "      <td>0.741</td>\n",
       "      <td>2.821</td>\n",
       "      <td>101.729</td>\n",
       "      <td>25m 48s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>28.683</td>\n",
       "      <td>3.700</td>\n",
       "      <td>0.765</td>\n",
       "      <td>2.726</td>\n",
       "      <td>110.138</td>\n",
       "      <td>48m 22s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>25.539</td>\n",
       "      <td>3.662</td>\n",
       "      <td>0.766</td>\n",
       "      <td>2.728</td>\n",
       "      <td>40.337</td>\n",
       "      <td>48m 1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>25.126</td>\n",
       "      <td>3.637</td>\n",
       "      <td>0.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>37.271</td>\n",
       "      <td>48m 33s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>24.740</td>\n",
       "      <td>3.597</td>\n",
       "      <td>0.770</td>\n",
       "      <td>2.663</td>\n",
       "      <td>35.827</td>\n",
       "      <td>48m 50s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>24.207</td>\n",
       "      <td>3.541</td>\n",
       "      <td>0.772</td>\n",
       "      <td>2.619</td>\n",
       "      <td>40.291</td>\n",
       "      <td>1h 38m 13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>24.170</td>\n",
       "      <td>3.569</td>\n",
       "      <td>0.769</td>\n",
       "      <td>2.654</td>\n",
       "      <td>39.435</td>\n",
       "      <td>1h 38m 10s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm       Year     N Features  Max Depth  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME      Run Time \n",
       "0  Random Forest  2015-2019       6         12             0.7                NO        32.944  4.015  0.722  2.881   69.833     11m 58s\n",
       "0  Random Forest  2015-2019       7         12             0.7                NO        33.314  4.042  0.722  3.047  102.497     11m 38s\n",
       "0  Random Forest  2015-2019       8         12             0.7                NO        32.862  3.992  0.728  2.985  117.944     12m 27s\n",
       "0  Random Forest  2015-2019       8         12             0.5                NO        30.801  3.854  0.741  2.821  101.729     25m 48s\n",
       "0  Random Forest  2015-2019       8         12             0.3                NO        28.683  3.700  0.765  2.726  110.138     48m 22s\n",
       "0  Random Forest  2015-2019       8         12             0.3               YES        25.539  3.662  0.766  2.728   40.337      48m 1s\n",
       "0  Random Forest  2015-2019       8         14             0.3               YES        25.126  3.637  0.768  2.714   37.271     48m 33s\n",
       "0  Random Forest  2015-2019       8         16             0.3               YES        24.740  3.597  0.770  2.663   35.827     48m 50s\n",
       "0  Random Forest  2015-2019       8         18             0.3               YES        24.207  3.541  0.772  2.619   40.291  1h 38m 13s\n",
       "0  Random Forest  2015-2019       8         20             0.3               YES        24.170  3.569  0.769  2.654   39.435  1h 38m 10s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather Algorithm statistics\n",
    "RFTime = ['11m 58s', '11m 38s', '12m 27s', '25m 48s', '48m 22s',  '48m 1s', '48m 33s', '48m 50s', '1h 38m 13s', '1h 38m 10s']\n",
    "\n",
    "RFData = pd.concat([RF_6_12_NO, RF_7_12_NO, RF_8_12_NO, RF_8_12_NO_5, RF_8_12_NO_3, RF_8_12_YES_3, RF_8_14_YES_3, RF_8_16_YES_3, RF_8_18_YES_3, RF_8_20_YES_3])\n",
    "RFData['Run Time'] = RFTime\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "display(RFData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_6_12_NO = GradientBoosting('Gradient Boosting', TotalYears, '2015-2019', 1, 1, 6, 12, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_7_12_NO = GradientBoosting('Gradient Boosting', TotalYears, '2015-2019', 1, 1, 7, 12, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_12_NO = GradientBoosting('Gradient Boosting', TotalYears, '2015-2019', 1, 1, 8, 12, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_12_NO_5 = GradientBoosting('Gradient Boosting', TotalYears, '2015-2019', 1, 1, 8, 12, 0.5, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_12_NO_3 = GradientBoosting('Gradient Boosting', TotalYears, '2015-2019', 1, 1, 8, 12, 0.3, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_12_YES_3 = GradientBoosting('Gradient Boosting', TotalYearsPM, '2015-2019', 1, 1, 8, 12, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_14_YES_3 = GradientBoosting('Gradient Boosting', TotalYearsPM, '2015-2019', 1, 1, 8, 14, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_16_YES_3 = GradientBoosting('Gradient Boosting', TotalYearsPM, '2015-2019', 1, 1, 8, 16, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_18_YES_3 = GradientBoosting('Gradient Boosting', TotalYearsPM, '2015-2019', 1, 1, 8, 18, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GB_8_20_YES_3 = GradientBoosting('Gradient Boosting', TotalYearsPM, '2015-2019', 1, 1, 8, 20, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.888</td>\n",
       "      <td>4.161</td>\n",
       "      <td>0.690</td>\n",
       "      <td>2.922</td>\n",
       "      <td>93.935</td>\n",
       "      <td>3m 38s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.385</td>\n",
       "      <td>4.129</td>\n",
       "      <td>0.696</td>\n",
       "      <td>2.957</td>\n",
       "      <td>92.646</td>\n",
       "      <td>3m 5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>34.970</td>\n",
       "      <td>4.049</td>\n",
       "      <td>0.712</td>\n",
       "      <td>2.928</td>\n",
       "      <td>90.867</td>\n",
       "      <td>3m 8s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>28.112</td>\n",
       "      <td>3.698</td>\n",
       "      <td>0.759</td>\n",
       "      <td>2.707</td>\n",
       "      <td>75.919</td>\n",
       "      <td>8m 57s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>25.986</td>\n",
       "      <td>3.612</td>\n",
       "      <td>0.782</td>\n",
       "      <td>2.648</td>\n",
       "      <td>50.205</td>\n",
       "      <td>17m 11s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>25.356</td>\n",
       "      <td>3.601</td>\n",
       "      <td>0.769</td>\n",
       "      <td>2.643</td>\n",
       "      <td>39.862</td>\n",
       "      <td>17m 15s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>23.963</td>\n",
       "      <td>3.559</td>\n",
       "      <td>0.768</td>\n",
       "      <td>2.647</td>\n",
       "      <td>36.793</td>\n",
       "      <td>21m 16s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>26.370</td>\n",
       "      <td>3.662</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2.658</td>\n",
       "      <td>40.525</td>\n",
       "      <td>28m 53s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>32.532</td>\n",
       "      <td>3.944</td>\n",
       "      <td>0.687</td>\n",
       "      <td>2.735</td>\n",
       "      <td>44.795</td>\n",
       "      <td>41m 50s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>31.880</td>\n",
       "      <td>4.209</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.227</td>\n",
       "      <td>37.325</td>\n",
       "      <td>49m 1s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algorithm         Year     N Features  Max Depth  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME   Run Time\n",
       "0  Gradient Boosting  2015-2019       6         12             0.7                NO        36.888  4.161  0.690  2.922  93.935   3m 38s\n",
       "0  Gradient Boosting  2015-2019       7         12             0.7                NO        36.385  4.129  0.696  2.957  92.646    3m 5s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.7                NO        34.970  4.049  0.712  2.928  90.867    3m 8s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.5                NO        28.112  3.698  0.759  2.707  75.919   8m 57s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.3                NO        25.986  3.612  0.782  2.648  50.205  17m 11s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.3               YES        25.356  3.601  0.769  2.643  39.862  17m 15s\n",
       "0  Gradient Boosting  2015-2019       8         14             0.3               YES        23.963  3.559  0.768  2.647  36.793  21m 16s\n",
       "0  Gradient Boosting  2015-2019       8         16             0.3               YES        26.370  3.662  0.749  2.658  40.525  28m 53s\n",
       "0  Gradient Boosting  2015-2019       8         18             0.3               YES        32.532  3.944  0.687  2.735  44.795  41m 50s\n",
       "0  Gradient Boosting  2015-2019       8         20             0.3               YES        31.880  4.209  0.687  3.227  37.325   49m 1s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather Algorithm statistics\n",
    "GBTime = ['3m 38s', '3m 5s', '3m 8s', '8m 57s', '17m 11s', '17m 15s', '21m 16s', '28m 53s', '41m 50s', '49m 1s']\n",
    "\n",
    "GBData = pd.concat([GB_6_12_NO, GB_7_12_NO, GB_8_12_NO, GB_8_12_NO_5, GB_8_12_NO_3, GB_8_12_YES_3, GB_8_14_YES_3, GB_8_16_YES_3, GB_8_18_YES_3, GB_8_20_YES_3])\n",
    "GBData['Run Time'] = GBTime \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "display(GBData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLP_6_7 = ANN('ANN', TotalYears, '2015-2019', 1, 1, 6, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLP_7_7 = ANN('ANN', TotalYears, '2015-2019', 1, 1, 7, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLP_8_7 = ANN('ANN', TotalYears, '2015-2019', 1, 1, 8, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLP_8_5 = ANN('ANN', TotalYears, '2015-2019', 1, 1, 8, 0.5, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLP_8_3 = ANN('ANN', TotalYears, '2015-2019', 1, 1, 8, 0.3, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLP_8_3_YES = ANN('ANN', TotalYearsPM, '2015-2019', 1, 1, 8, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>40.708</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.652</td>\n",
       "      <td>3.365</td>\n",
       "      <td>96.488</td>\n",
       "      <td>1m 12s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>31.084</td>\n",
       "      <td>3.991</td>\n",
       "      <td>0.739</td>\n",
       "      <td>2.974</td>\n",
       "      <td>85.455</td>\n",
       "      <td>1m 11s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>31.286</td>\n",
       "      <td>3.956</td>\n",
       "      <td>0.740</td>\n",
       "      <td>2.955</td>\n",
       "      <td>90.318</td>\n",
       "      <td>1m 13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>30.592</td>\n",
       "      <td>3.900</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2.891</td>\n",
       "      <td>80.842</td>\n",
       "      <td>2m 2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>29.117</td>\n",
       "      <td>3.820</td>\n",
       "      <td>0.748</td>\n",
       "      <td>2.825</td>\n",
       "      <td>83.062</td>\n",
       "      <td>2m 56s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>27.012</td>\n",
       "      <td>3.802</td>\n",
       "      <td>0.752</td>\n",
       "      <td>2.871</td>\n",
       "      <td>35.444</td>\n",
       "      <td>2m 55s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm    Year     N Features  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME   Run Time\n",
       "0     ANN    2015-2019       6             0.7                NO        40.708  4.529  0.652  3.365  96.488  1m 12s \n",
       "0     ANN    2015-2019       7             0.7                NO        31.084  3.991  0.739  2.974  85.455  1m 11s \n",
       "0     ANN    2015-2019       8             0.7                NO        31.286  3.956  0.740  2.955  90.318  1m 13s \n",
       "0     ANN    2015-2019       8             0.5                NO        30.592  3.900  0.749  2.891  80.842   2m 2s \n",
       "0     ANN    2015-2019       8             0.3                NO        29.117  3.820  0.748  2.825  83.062  2m 56s \n",
       "0     ANN    2015-2019       8             0.3               YES        27.012  3.802  0.752  2.871  35.444  2m 55s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather Algorithm statistics\n",
    "MLPTime = ['1m 12s', '1m 11s', '1m 13s', '2m 2s', '2m 56s', '2m 55s']\n",
    "\n",
    "MLPData = pd.concat([MLP_6_7, MLP_7_7, MLP_8_7, MLP_8_5, MLP_8_3, MLP_8_3_YES])\n",
    "MLPData['Run Time'] = MLPTime \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "display(MLPData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR_6_7 = LRegress('Linear Regression', TotalYears, '2015-2019', 1, 1, 6, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR_7_7 = LRegress('Linear Regression', TotalYears, '2015-2019', 1, 1, 7, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR_8_7 = LRegress('Linear Regression', TotalYears, '2015-2019', 1, 1, 8, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR_8_5 = LRegress('Linear Regression', TotalYears, '2015-2019', 1, 1, 8, 0.5, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR_8_3 = LRegress('Linear Regression', TotalYears, '2015-2019', 1, 1, 8, 0.3, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LP_8_3_YES = LRegress('Linear Regression', TotalYearsPM, '2015-2019', 1, 1, 8, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>52.470</td>\n",
       "      <td>5.264</td>\n",
       "      <td>0.551</td>\n",
       "      <td>4.233</td>\n",
       "      <td>121.996</td>\n",
       "      <td>4m 40s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>54.418</td>\n",
       "      <td>5.251</td>\n",
       "      <td>0.546</td>\n",
       "      <td>4.189</td>\n",
       "      <td>122.548</td>\n",
       "      <td>4m 2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>53.413</td>\n",
       "      <td>5.268</td>\n",
       "      <td>0.551</td>\n",
       "      <td>4.211</td>\n",
       "      <td>115.834</td>\n",
       "      <td>4m 4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>54.687</td>\n",
       "      <td>5.252</td>\n",
       "      <td>0.549</td>\n",
       "      <td>4.144</td>\n",
       "      <td>122.508</td>\n",
       "      <td>11m 42s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>55.107</td>\n",
       "      <td>5.245</td>\n",
       "      <td>0.546</td>\n",
       "      <td>4.156</td>\n",
       "      <td>115.782</td>\n",
       "      <td>24m 18s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>45.371</td>\n",
       "      <td>5.090</td>\n",
       "      <td>0.573</td>\n",
       "      <td>4.094</td>\n",
       "      <td>42.098</td>\n",
       "      <td>24m 34s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algorithm         Year     N Features  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME    Run Time\n",
       "0  Linear Regression  2015-2019       6             0.7                NO        52.470  5.264  0.551  4.233  121.996   4m 40s\n",
       "0  Linear Regression  2015-2019       7             0.7                NO        54.418  5.251  0.546  4.189  122.548    4m 2s\n",
       "0  Linear Regression  2015-2019       8             0.7                NO        53.413  5.268  0.551  4.211  115.834    4m 4s\n",
       "0  Linear Regression  2015-2019       8             0.5                NO        54.687  5.252  0.549  4.144  122.508  11m 42s\n",
       "0  Linear Regression  2015-2019       8             0.3                NO        55.107  5.245  0.546  4.156  115.782  24m 18s\n",
       "0  Linear Regression  2015-2019       8             0.3               YES        45.371  5.090  0.573  4.094   42.098  24m 34s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather Algorithm statistics\n",
    "LRTime = ['4m 40s', '4m 2s', '4m 4s', '11m 42s', '24m 18s', '24m 34s']\n",
    "\n",
    "LRData = pd.concat([LR_6_7, LR_7_7, LR_8_7, LR_8_5, LR_8_3, LP_8_3_YES])\n",
    "LRData['Run Time'] = LRTime \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "display(LRData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVM_6_7 = SVM('SVM', TotalYears, '2015-2019', 1, 1, 6, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVM_7_7 = SVM('SVM', TotalYears, '2015-2019', 1, 1, 7, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVM_8_7 = SVM('SVM', TotalYears, '2015-2019', 1, 1, 8, 0.7, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVM_8_5 = SVM('SVM', TotalYears, '2015-2019', 1, 1, 8, 0.5, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVM_8_3 = SVM('SVM', TotalYears, '2015-2019', 1, 1, 8, 0.3, 'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVM_8_3_YES = SVM('SVM', TotalYearsPM, '2015-2019', 1, 1, 8, 0.3, 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>44.601</td>\n",
       "      <td>4.580</td>\n",
       "      <td>0.620</td>\n",
       "      <td>3.309</td>\n",
       "      <td>115.233</td>\n",
       "      <td>1m 22s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>38.340</td>\n",
       "      <td>4.041</td>\n",
       "      <td>0.680</td>\n",
       "      <td>2.854</td>\n",
       "      <td>121.837</td>\n",
       "      <td>1m 13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>38.287</td>\n",
       "      <td>4.043</td>\n",
       "      <td>0.683</td>\n",
       "      <td>2.834</td>\n",
       "      <td>120.732</td>\n",
       "      <td>1m 17s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.750</td>\n",
       "      <td>3.964</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2.761</td>\n",
       "      <td>115.940</td>\n",
       "      <td>4m 1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.954</td>\n",
       "      <td>3.912</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2.711</td>\n",
       "      <td>114.815</td>\n",
       "      <td>7m 15s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>27.820</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.738</td>\n",
       "      <td>2.686</td>\n",
       "      <td>40.637</td>\n",
       "      <td>7m 13s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm    Year     N Features  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME    Run Time\n",
       "0     SVM    2015-2019       6             0.7                NO        44.601  4.580  0.620  3.309  115.233  1m 22s \n",
       "0     SVM    2015-2019       7             0.7                NO        38.340  4.041  0.680  2.854  121.837  1m 13s \n",
       "0     SVM    2015-2019       8             0.7                NO        38.287  4.043  0.683  2.834  120.732  1m 17s \n",
       "0     SVM    2015-2019       8             0.5                NO        36.750  3.964  0.700  2.761  115.940   4m 1s \n",
       "0     SVM    2015-2019       8             0.3                NO        36.954  3.912  0.704  2.711  114.815  7m 15s \n",
       "0     SVM    2015-2019       8             0.3               YES        27.820  3.738  0.738  2.686   40.637  7m 13s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather Algorithm statistics\n",
    "SVMTime = ['1m 22s', '1m 13s', '1m 17s', '4m 1s', '7m 15s', '7m 13s']\n",
    "\n",
    "SVMData = pd.concat([SVM_6_7, SVM_7_7, SVM_8_7, SVM_8_5, SVM_8_3, SVM_8_3_YES])\n",
    "SVMData['Run Time'] = SVMTime \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "display(SVMData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Tables of Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>32.944</td>\n",
       "      <td>4.015</td>\n",
       "      <td>0.722</td>\n",
       "      <td>2.881</td>\n",
       "      <td>69.833</td>\n",
       "      <td>11m 58s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>33.314</td>\n",
       "      <td>4.042</td>\n",
       "      <td>0.722</td>\n",
       "      <td>3.047</td>\n",
       "      <td>102.497</td>\n",
       "      <td>11m 38s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>32.862</td>\n",
       "      <td>3.992</td>\n",
       "      <td>0.728</td>\n",
       "      <td>2.985</td>\n",
       "      <td>117.944</td>\n",
       "      <td>12m 27s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>30.801</td>\n",
       "      <td>3.854</td>\n",
       "      <td>0.741</td>\n",
       "      <td>2.821</td>\n",
       "      <td>101.729</td>\n",
       "      <td>25m 48s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>28.683</td>\n",
       "      <td>3.700</td>\n",
       "      <td>0.765</td>\n",
       "      <td>2.726</td>\n",
       "      <td>110.138</td>\n",
       "      <td>48m 22s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>25.539</td>\n",
       "      <td>3.662</td>\n",
       "      <td>0.766</td>\n",
       "      <td>2.728</td>\n",
       "      <td>40.337</td>\n",
       "      <td>48m 1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>25.126</td>\n",
       "      <td>3.637</td>\n",
       "      <td>0.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>37.271</td>\n",
       "      <td>48m 33s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>24.740</td>\n",
       "      <td>3.597</td>\n",
       "      <td>0.770</td>\n",
       "      <td>2.663</td>\n",
       "      <td>35.827</td>\n",
       "      <td>48m 50s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>24.207</td>\n",
       "      <td>3.541</td>\n",
       "      <td>0.772</td>\n",
       "      <td>2.619</td>\n",
       "      <td>40.291</td>\n",
       "      <td>1h 38m 13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>24.170</td>\n",
       "      <td>3.569</td>\n",
       "      <td>0.769</td>\n",
       "      <td>2.654</td>\n",
       "      <td>39.435</td>\n",
       "      <td>1h 38m 10s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm       Year     N Features  Max Depth  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME      Run Time \n",
       "0  Random Forest  2015-2019       6         12             0.7                NO        32.944  4.015  0.722  2.881   69.833     11m 58s\n",
       "0  Random Forest  2015-2019       7         12             0.7                NO        33.314  4.042  0.722  3.047  102.497     11m 38s\n",
       "0  Random Forest  2015-2019       8         12             0.7                NO        32.862  3.992  0.728  2.985  117.944     12m 27s\n",
       "0  Random Forest  2015-2019       8         12             0.5                NO        30.801  3.854  0.741  2.821  101.729     25m 48s\n",
       "0  Random Forest  2015-2019       8         12             0.3                NO        28.683  3.700  0.765  2.726  110.138     48m 22s\n",
       "0  Random Forest  2015-2019       8         12             0.3               YES        25.539  3.662  0.766  2.728   40.337      48m 1s\n",
       "0  Random Forest  2015-2019       8         14             0.3               YES        25.126  3.637  0.768  2.714   37.271     48m 33s\n",
       "0  Random Forest  2015-2019       8         16             0.3               YES        24.740  3.597  0.770  2.663   35.827     48m 50s\n",
       "0  Random Forest  2015-2019       8         18             0.3               YES        24.207  3.541  0.772  2.619   40.291  1h 38m 13s\n",
       "0  Random Forest  2015-2019       8         20             0.3               YES        24.170  3.569  0.769  2.654   39.435  1h 38m 10s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.888</td>\n",
       "      <td>4.161</td>\n",
       "      <td>0.690</td>\n",
       "      <td>2.922</td>\n",
       "      <td>93.935</td>\n",
       "      <td>3m 38s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.385</td>\n",
       "      <td>4.129</td>\n",
       "      <td>0.696</td>\n",
       "      <td>2.957</td>\n",
       "      <td>92.646</td>\n",
       "      <td>3m 5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>34.970</td>\n",
       "      <td>4.049</td>\n",
       "      <td>0.712</td>\n",
       "      <td>2.928</td>\n",
       "      <td>90.867</td>\n",
       "      <td>3m 8s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>28.112</td>\n",
       "      <td>3.698</td>\n",
       "      <td>0.759</td>\n",
       "      <td>2.707</td>\n",
       "      <td>75.919</td>\n",
       "      <td>8m 57s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>25.986</td>\n",
       "      <td>3.612</td>\n",
       "      <td>0.782</td>\n",
       "      <td>2.648</td>\n",
       "      <td>50.205</td>\n",
       "      <td>17m 11s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>25.356</td>\n",
       "      <td>3.601</td>\n",
       "      <td>0.769</td>\n",
       "      <td>2.643</td>\n",
       "      <td>39.862</td>\n",
       "      <td>17m 15s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>23.963</td>\n",
       "      <td>3.559</td>\n",
       "      <td>0.768</td>\n",
       "      <td>2.647</td>\n",
       "      <td>36.793</td>\n",
       "      <td>21m 16s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>26.370</td>\n",
       "      <td>3.662</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2.658</td>\n",
       "      <td>40.525</td>\n",
       "      <td>28m 53s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>32.532</td>\n",
       "      <td>3.944</td>\n",
       "      <td>0.687</td>\n",
       "      <td>2.735</td>\n",
       "      <td>44.795</td>\n",
       "      <td>41m 50s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>31.880</td>\n",
       "      <td>4.209</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.227</td>\n",
       "      <td>37.325</td>\n",
       "      <td>49m 1s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algorithm         Year     N Features  Max Depth  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME   Run Time\n",
       "0  Gradient Boosting  2015-2019       6         12             0.7                NO        36.888  4.161  0.690  2.922  93.935   3m 38s\n",
       "0  Gradient Boosting  2015-2019       7         12             0.7                NO        36.385  4.129  0.696  2.957  92.646    3m 5s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.7                NO        34.970  4.049  0.712  2.928  90.867    3m 8s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.5                NO        28.112  3.698  0.759  2.707  75.919   8m 57s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.3                NO        25.986  3.612  0.782  2.648  50.205  17m 11s\n",
       "0  Gradient Boosting  2015-2019       8         12             0.3               YES        25.356  3.601  0.769  2.643  39.862  17m 15s\n",
       "0  Gradient Boosting  2015-2019       8         14             0.3               YES        23.963  3.559  0.768  2.647  36.793  21m 16s\n",
       "0  Gradient Boosting  2015-2019       8         16             0.3               YES        26.370  3.662  0.749  2.658  40.525  28m 53s\n",
       "0  Gradient Boosting  2015-2019       8         18             0.3               YES        32.532  3.944  0.687  2.735  44.795  41m 50s\n",
       "0  Gradient Boosting  2015-2019       8         20             0.3               YES        31.880  4.209  0.687  3.227  37.325   49m 1s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>40.708</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.652</td>\n",
       "      <td>3.365</td>\n",
       "      <td>96.488</td>\n",
       "      <td>1m 12s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>31.084</td>\n",
       "      <td>3.991</td>\n",
       "      <td>0.739</td>\n",
       "      <td>2.974</td>\n",
       "      <td>85.455</td>\n",
       "      <td>1m 11s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>31.286</td>\n",
       "      <td>3.956</td>\n",
       "      <td>0.740</td>\n",
       "      <td>2.955</td>\n",
       "      <td>90.318</td>\n",
       "      <td>1m 13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>30.592</td>\n",
       "      <td>3.900</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2.891</td>\n",
       "      <td>80.842</td>\n",
       "      <td>2m 2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>29.117</td>\n",
       "      <td>3.820</td>\n",
       "      <td>0.748</td>\n",
       "      <td>2.825</td>\n",
       "      <td>83.062</td>\n",
       "      <td>2m 56s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>27.012</td>\n",
       "      <td>3.802</td>\n",
       "      <td>0.752</td>\n",
       "      <td>2.871</td>\n",
       "      <td>35.444</td>\n",
       "      <td>2m 55s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm    Year     N Features  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME   Run Time\n",
       "0     ANN    2015-2019       6             0.7                NO        40.708  4.529  0.652  3.365  96.488  1m 12s \n",
       "0     ANN    2015-2019       7             0.7                NO        31.084  3.991  0.739  2.974  85.455  1m 11s \n",
       "0     ANN    2015-2019       8             0.7                NO        31.286  3.956  0.740  2.955  90.318  1m 13s \n",
       "0     ANN    2015-2019       8             0.5                NO        30.592  3.900  0.749  2.891  80.842   2m 2s \n",
       "0     ANN    2015-2019       8             0.3                NO        29.117  3.820  0.748  2.825  83.062  2m 56s \n",
       "0     ANN    2015-2019       8             0.3               YES        27.012  3.802  0.752  2.871  35.444  2m 55s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>52.470</td>\n",
       "      <td>5.264</td>\n",
       "      <td>0.551</td>\n",
       "      <td>4.233</td>\n",
       "      <td>121.996</td>\n",
       "      <td>4m 40s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>54.418</td>\n",
       "      <td>5.251</td>\n",
       "      <td>0.546</td>\n",
       "      <td>4.189</td>\n",
       "      <td>122.548</td>\n",
       "      <td>4m 2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>53.413</td>\n",
       "      <td>5.268</td>\n",
       "      <td>0.551</td>\n",
       "      <td>4.211</td>\n",
       "      <td>115.834</td>\n",
       "      <td>4m 4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>54.687</td>\n",
       "      <td>5.252</td>\n",
       "      <td>0.549</td>\n",
       "      <td>4.144</td>\n",
       "      <td>122.508</td>\n",
       "      <td>11m 42s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>55.107</td>\n",
       "      <td>5.245</td>\n",
       "      <td>0.546</td>\n",
       "      <td>4.156</td>\n",
       "      <td>115.782</td>\n",
       "      <td>24m 18s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>45.371</td>\n",
       "      <td>5.090</td>\n",
       "      <td>0.573</td>\n",
       "      <td>4.094</td>\n",
       "      <td>42.098</td>\n",
       "      <td>24m 34s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algorithm         Year     N Features  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME    Run Time\n",
       "0  Linear Regression  2015-2019       6             0.7                NO        52.470  5.264  0.551  4.233  121.996   4m 40s\n",
       "0  Linear Regression  2015-2019       7             0.7                NO        54.418  5.251  0.546  4.189  122.548    4m 2s\n",
       "0  Linear Regression  2015-2019       8             0.7                NO        53.413  5.268  0.551  4.211  115.834    4m 4s\n",
       "0  Linear Regression  2015-2019       8             0.5                NO        54.687  5.252  0.549  4.144  122.508  11m 42s\n",
       "0  Linear Regression  2015-2019       8             0.3                NO        55.107  5.245  0.546  4.156  115.782  24m 18s\n",
       "0  Linear Regression  2015-2019       8             0.3               YES        45.371  5.090  0.573  4.094   42.098  24m 34s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Year</th>\n",
       "      <th>N Features</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>44.601</td>\n",
       "      <td>4.580</td>\n",
       "      <td>0.620</td>\n",
       "      <td>3.309</td>\n",
       "      <td>115.233</td>\n",
       "      <td>1m 22s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>38.340</td>\n",
       "      <td>4.041</td>\n",
       "      <td>0.680</td>\n",
       "      <td>2.854</td>\n",
       "      <td>121.837</td>\n",
       "      <td>1m 13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NO</td>\n",
       "      <td>38.287</td>\n",
       "      <td>4.043</td>\n",
       "      <td>0.683</td>\n",
       "      <td>2.834</td>\n",
       "      <td>120.732</td>\n",
       "      <td>1m 17s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.750</td>\n",
       "      <td>3.964</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2.761</td>\n",
       "      <td>115.940</td>\n",
       "      <td>4m 1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NO</td>\n",
       "      <td>36.954</td>\n",
       "      <td>3.912</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2.711</td>\n",
       "      <td>114.815</td>\n",
       "      <td>7m 15s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2015-2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>YES</td>\n",
       "      <td>27.820</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.738</td>\n",
       "      <td>2.686</td>\n",
       "      <td>40.637</td>\n",
       "      <td>7m 13s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm    Year     N Features  Test-Train Split PM10 > 70 Removed    MSE    MAE    R2    MEAE     ME    Run Time\n",
       "0     SVM    2015-2019       6             0.7                NO        44.601  4.580  0.620  3.309  115.233  1m 22s \n",
       "0     SVM    2015-2019       7             0.7                NO        38.340  4.041  0.680  2.854  121.837  1m 13s \n",
       "0     SVM    2015-2019       8             0.7                NO        38.287  4.043  0.683  2.834  120.732  1m 17s \n",
       "0     SVM    2015-2019       8             0.5                NO        36.750  3.964  0.700  2.761  115.940   4m 1s \n",
       "0     SVM    2015-2019       8             0.3                NO        36.954  3.912  0.704  2.711  114.815  7m 15s \n",
       "0     SVM    2015-2019       8             0.3               YES        27.820  3.738  0.738  2.686   40.637  7m 13s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check that they all look reasonable\n",
    "display(RFData)\n",
    "display(GBData)\n",
    "display(MLPData)\n",
    "display(LRData)\n",
    "display(SVMData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MAE</th>\n",
       "      <th>ME</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>N Features</th>\n",
       "      <th>PM10 &gt; 70 Removed</th>\n",
       "      <th>R2</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Test-Train Split</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>4.015</td>\n",
       "      <td>69.833</td>\n",
       "      <td>2.881</td>\n",
       "      <td>32.944</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.722</td>\n",
       "      <td>11m 58s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>4.042</td>\n",
       "      <td>102.497</td>\n",
       "      <td>3.047</td>\n",
       "      <td>33.314</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.722</td>\n",
       "      <td>11m 38s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.992</td>\n",
       "      <td>117.944</td>\n",
       "      <td>2.985</td>\n",
       "      <td>32.862</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.728</td>\n",
       "      <td>12m 27s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.854</td>\n",
       "      <td>101.729</td>\n",
       "      <td>2.821</td>\n",
       "      <td>30.801</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.741</td>\n",
       "      <td>25m 48s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.700</td>\n",
       "      <td>110.138</td>\n",
       "      <td>2.726</td>\n",
       "      <td>28.683</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.765</td>\n",
       "      <td>48m 22s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.662</td>\n",
       "      <td>40.337</td>\n",
       "      <td>2.728</td>\n",
       "      <td>25.539</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.766</td>\n",
       "      <td>48m 1s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.637</td>\n",
       "      <td>37.271</td>\n",
       "      <td>2.714</td>\n",
       "      <td>25.126</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.768</td>\n",
       "      <td>48m 33s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.597</td>\n",
       "      <td>35.827</td>\n",
       "      <td>2.663</td>\n",
       "      <td>24.740</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.770</td>\n",
       "      <td>48m 50s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.541</td>\n",
       "      <td>40.291</td>\n",
       "      <td>2.619</td>\n",
       "      <td>24.207</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.772</td>\n",
       "      <td>1h 38m 13s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.569</td>\n",
       "      <td>39.435</td>\n",
       "      <td>2.654</td>\n",
       "      <td>24.170</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.769</td>\n",
       "      <td>1h 38m 10s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>4.161</td>\n",
       "      <td>93.935</td>\n",
       "      <td>2.922</td>\n",
       "      <td>36.888</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.690</td>\n",
       "      <td>3m 38s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>4.129</td>\n",
       "      <td>92.646</td>\n",
       "      <td>2.957</td>\n",
       "      <td>36.385</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.696</td>\n",
       "      <td>3m 5s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>4.049</td>\n",
       "      <td>90.867</td>\n",
       "      <td>2.928</td>\n",
       "      <td>34.970</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3m 8s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>3.698</td>\n",
       "      <td>75.919</td>\n",
       "      <td>2.707</td>\n",
       "      <td>28.112</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.759</td>\n",
       "      <td>8m 57s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>3.612</td>\n",
       "      <td>50.205</td>\n",
       "      <td>2.648</td>\n",
       "      <td>25.986</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.782</td>\n",
       "      <td>17m 11s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>3.601</td>\n",
       "      <td>39.862</td>\n",
       "      <td>2.643</td>\n",
       "      <td>25.356</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.769</td>\n",
       "      <td>17m 15s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>3.559</td>\n",
       "      <td>36.793</td>\n",
       "      <td>2.647</td>\n",
       "      <td>23.963</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.768</td>\n",
       "      <td>21m 16s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>3.662</td>\n",
       "      <td>40.525</td>\n",
       "      <td>2.658</td>\n",
       "      <td>26.370</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.749</td>\n",
       "      <td>28m 53s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>3.944</td>\n",
       "      <td>44.795</td>\n",
       "      <td>2.735</td>\n",
       "      <td>32.532</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.687</td>\n",
       "      <td>41m 50s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>4.209</td>\n",
       "      <td>37.325</td>\n",
       "      <td>3.227</td>\n",
       "      <td>31.880</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.687</td>\n",
       "      <td>49m 1s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>4.529</td>\n",
       "      <td>96.488</td>\n",
       "      <td>3.365</td>\n",
       "      <td>40.708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1m 12s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>3.991</td>\n",
       "      <td>85.455</td>\n",
       "      <td>2.974</td>\n",
       "      <td>31.084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.739</td>\n",
       "      <td>1m 11s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>3.956</td>\n",
       "      <td>90.318</td>\n",
       "      <td>2.955</td>\n",
       "      <td>31.286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1m 13s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>3.900</td>\n",
       "      <td>80.842</td>\n",
       "      <td>2.891</td>\n",
       "      <td>30.592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2m 2s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>3.820</td>\n",
       "      <td>83.062</td>\n",
       "      <td>2.825</td>\n",
       "      <td>29.117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.748</td>\n",
       "      <td>2m 56s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>3.802</td>\n",
       "      <td>35.444</td>\n",
       "      <td>2.871</td>\n",
       "      <td>27.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.752</td>\n",
       "      <td>2m 55s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.264</td>\n",
       "      <td>121.996</td>\n",
       "      <td>4.233</td>\n",
       "      <td>52.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.551</td>\n",
       "      <td>4m 40s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.251</td>\n",
       "      <td>122.548</td>\n",
       "      <td>4.189</td>\n",
       "      <td>54.418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.546</td>\n",
       "      <td>4m 2s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.268</td>\n",
       "      <td>115.834</td>\n",
       "      <td>4.211</td>\n",
       "      <td>53.413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.551</td>\n",
       "      <td>4m 4s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.252</td>\n",
       "      <td>122.508</td>\n",
       "      <td>4.144</td>\n",
       "      <td>54.687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.549</td>\n",
       "      <td>11m 42s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.245</td>\n",
       "      <td>115.782</td>\n",
       "      <td>4.156</td>\n",
       "      <td>55.107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.546</td>\n",
       "      <td>24m 18s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.090</td>\n",
       "      <td>42.098</td>\n",
       "      <td>4.094</td>\n",
       "      <td>45.371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.573</td>\n",
       "      <td>24m 34s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4.580</td>\n",
       "      <td>115.233</td>\n",
       "      <td>3.309</td>\n",
       "      <td>44.601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1m 22s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4.041</td>\n",
       "      <td>121.837</td>\n",
       "      <td>2.854</td>\n",
       "      <td>38.340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.680</td>\n",
       "      <td>1m 13s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4.043</td>\n",
       "      <td>120.732</td>\n",
       "      <td>2.834</td>\n",
       "      <td>38.287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.683</td>\n",
       "      <td>1m 17s</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3.964</td>\n",
       "      <td>115.940</td>\n",
       "      <td>2.761</td>\n",
       "      <td>36.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.700</td>\n",
       "      <td>4m 1s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3.912</td>\n",
       "      <td>114.815</td>\n",
       "      <td>2.711</td>\n",
       "      <td>36.954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.704</td>\n",
       "      <td>7m 15s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3.738</td>\n",
       "      <td>40.637</td>\n",
       "      <td>2.686</td>\n",
       "      <td>27.820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.738</td>\n",
       "      <td>7m 13s</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2015-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algorithm        MAE     ME     MEAE     MSE   Max Depth  N Features PM10 > 70 Removed   R2     Run Time   Test-Train Split    Year   \n",
       "0      Random Forest  4.015   69.833  2.881  32.944    12.0          6              NO        0.722     11m 58s         0.7        2015-2019\n",
       "0      Random Forest  4.042  102.497  3.047  33.314    12.0          7              NO        0.722     11m 38s         0.7        2015-2019\n",
       "0      Random Forest  3.992  117.944  2.985  32.862    12.0          8              NO        0.728     12m 27s         0.7        2015-2019\n",
       "0      Random Forest  3.854  101.729  2.821  30.801    12.0          8              NO        0.741     25m 48s         0.5        2015-2019\n",
       "0      Random Forest  3.700  110.138  2.726  28.683    12.0          8              NO        0.765     48m 22s         0.3        2015-2019\n",
       "0      Random Forest  3.662   40.337  2.728  25.539    12.0          8             YES        0.766      48m 1s         0.3        2015-2019\n",
       "0      Random Forest  3.637   37.271  2.714  25.126    14.0          8             YES        0.768     48m 33s         0.3        2015-2019\n",
       "0      Random Forest  3.597   35.827  2.663  24.740    16.0          8             YES        0.770     48m 50s         0.3        2015-2019\n",
       "0      Random Forest  3.541   40.291  2.619  24.207    18.0          8             YES        0.772  1h 38m 13s         0.3        2015-2019\n",
       "0      Random Forest  3.569   39.435  2.654  24.170    20.0          8             YES        0.769  1h 38m 10s         0.3        2015-2019\n",
       "0  Gradient Boosting  4.161   93.935  2.922  36.888    12.0          6              NO        0.690      3m 38s         0.7        2015-2019\n",
       "0  Gradient Boosting  4.129   92.646  2.957  36.385    12.0          7              NO        0.696       3m 5s         0.7        2015-2019\n",
       "0  Gradient Boosting  4.049   90.867  2.928  34.970    12.0          8              NO        0.712       3m 8s         0.7        2015-2019\n",
       "0  Gradient Boosting  3.698   75.919  2.707  28.112    12.0          8              NO        0.759      8m 57s         0.5        2015-2019\n",
       "0  Gradient Boosting  3.612   50.205  2.648  25.986    12.0          8              NO        0.782     17m 11s         0.3        2015-2019\n",
       "0  Gradient Boosting  3.601   39.862  2.643  25.356    12.0          8             YES        0.769     17m 15s         0.3        2015-2019\n",
       "0  Gradient Boosting  3.559   36.793  2.647  23.963    14.0          8             YES        0.768     21m 16s         0.3        2015-2019\n",
       "0  Gradient Boosting  3.662   40.525  2.658  26.370    16.0          8             YES        0.749     28m 53s         0.3        2015-2019\n",
       "0  Gradient Boosting  3.944   44.795  2.735  32.532    18.0          8             YES        0.687     41m 50s         0.3        2015-2019\n",
       "0  Gradient Boosting  4.209   37.325  3.227  31.880    20.0          8             YES        0.687      49m 1s         0.3        2015-2019\n",
       "0                ANN  4.529   96.488  3.365  40.708     NaN          6              NO        0.652      1m 12s         0.7        2015-2019\n",
       "0                ANN  3.991   85.455  2.974  31.084     NaN          7              NO        0.739      1m 11s         0.7        2015-2019\n",
       "0                ANN  3.956   90.318  2.955  31.286     NaN          8              NO        0.740      1m 13s         0.7        2015-2019\n",
       "0                ANN  3.900   80.842  2.891  30.592     NaN          8              NO        0.749       2m 2s         0.5        2015-2019\n",
       "0                ANN  3.820   83.062  2.825  29.117     NaN          8              NO        0.748      2m 56s         0.3        2015-2019\n",
       "0                ANN  3.802   35.444  2.871  27.012     NaN          8             YES        0.752      2m 55s         0.3        2015-2019\n",
       "0  Linear Regression  5.264  121.996  4.233  52.470     NaN          6              NO        0.551      4m 40s         0.7        2015-2019\n",
       "0  Linear Regression  5.251  122.548  4.189  54.418     NaN          7              NO        0.546       4m 2s         0.7        2015-2019\n",
       "0  Linear Regression  5.268  115.834  4.211  53.413     NaN          8              NO        0.551       4m 4s         0.7        2015-2019\n",
       "0  Linear Regression  5.252  122.508  4.144  54.687     NaN          8              NO        0.549     11m 42s         0.5        2015-2019\n",
       "0  Linear Regression  5.245  115.782  4.156  55.107     NaN          8              NO        0.546     24m 18s         0.3        2015-2019\n",
       "0  Linear Regression  5.090   42.098  4.094  45.371     NaN          8             YES        0.573     24m 34s         0.3        2015-2019\n",
       "0                SVM  4.580  115.233  3.309  44.601     NaN          6              NO        0.620      1m 22s         0.7        2015-2019\n",
       "0                SVM  4.041  121.837  2.854  38.340     NaN          7              NO        0.680      1m 13s         0.7        2015-2019\n",
       "0                SVM  4.043  120.732  2.834  38.287     NaN          8              NO        0.683      1m 17s         0.7        2015-2019\n",
       "0                SVM  3.964  115.940  2.761  36.750     NaN          8              NO        0.700       4m 1s         0.5        2015-2019\n",
       "0                SVM  3.912  114.815  2.711  36.954     NaN          8              NO        0.704      7m 15s         0.3        2015-2019\n",
       "0                SVM  3.738   40.637  2.686  27.820     NaN          8             YES        0.738      7m 13s         0.3        2015-2019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PM25incData = pd.concat([RFData, GBData, MLPData, LRData, SVMData])\n",
    "display(PM25incData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV of results\n",
    "PM25incData.to_csv('PM10_Prediction_Results_including_PM25', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
